{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b106abc-4bf2-4163-8175-727cb749b189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#1_How to create Pyspark Dataframe using python list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b8eb6b3-3b8e-4f0c-bde9-0de8cf423059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4fe6a87-c257-4afe-9681-7f817eeeee17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark DataFrames\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5218f017-7980-4b26-8a7a-a3eaa02894ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1_Create a DataFrame from a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "986705f5-dd7f-4d80-993d-3995a0a9883e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [],
   "source": [
    "# List of Tuples\n",
    "data = [(1, \"Mustaq\", 32, \"ADF\"),\n",
    "        (2, \"Ali\", 30, \"Databricks\"),\n",
    "        (3, \"Ahmed\", 35, \"Spark\"),\n",
    "        (4, \"Adnan\", 28, \"Python\"),\n",
    "        (5, \"Ishan\", 25, \"Java\")]\n",
    "\n",
    "# Define column Names\n",
    "columns = [\"id\", \"name\", \"age\", \"department\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd308fbd-842d-431e-8738-7ff831750044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Display DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73d31146-0c18-489a-bdd4-bae0c38725e5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [],
   "source": [
    "#List of Tuples\n",
    "data = [(1, \"Mustaq\", 32, \"ADF\"),\n",
    "        (2, \"Ali\", 30, \"Databricks\"),\n",
    "        (3, \"Ahmed\", 35, \"Spark\"),\n",
    "        (4, \"Adnan\", 28, \"Python\"),\n",
    "        (5, \"Ishan\", 25, \"Java\")]\n",
    "\n",
    "# Create DataFrame\n",
    "df1 = spark.createDataFrame(data, 'Id int, Name string, Age int, Department string')\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bca49fcc-b600-44f7-877b-e4d25a67b0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2_Create DataFrame from a List of Lists\n",
    "  - If your list contains list instead of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbf6b5ec-1151-41c4-9653-b8d525d5cd5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list of lists\n",
    "data = [[1, \"Mustaq\", 32, \"ADF\"],\n",
    "        [2, \"Ali\", 30, \"Databricks\"],\n",
    "        [3, \"Ahmed\", 35, \"Spark\"],\n",
    "        [4, \"Adnan\", 28, \"Python\"],\n",
    "        [5, \"Ishan\", 25, \"Java\"]]\n",
    "\n",
    "# Define column Names\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df2 = spark.createDataFrame(data, schema=columns)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aef79476-837d-4fb8-adc2-d0e23b01545b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3_Create a DataFrame using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f20e48b6-a9f2-41c5-a2c1-df45081ceddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [{'Name' : 'Mustaq', 'Id' : 'A001', 'Country' : 'India'},\n",
    "         {'Name' : 'Ali', 'Id' : 'A002', 'Country' : 'USA'},\n",
    "         {'Name' : 'Ahmed', 'Id' : 'A003', 'Country' : 'Canada'},\n",
    "         {'Name' : 'Adnan', 'Id' : 'A004', 'Country' : 'UK'},\n",
    "         {'Name' : 'Ishan', 'Id' : 'A005', 'Country' : 'Australia'}]\n",
    "\n",
    "df_dict = spark.createDataFrame(data)\n",
    "display(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a624a6-6686-4e0b-ba82-c369b181efad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4_Create a DataFrame from a simple list\n",
    "- If your list contains a single column, you can still use createDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e2ce59e-de67-4555-b7fa-d5979fda92bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [],
   "source": [
    "data = [1, 23, 35, 45, 58, 69, 72, 80, 91, 3]\n",
    "\n",
    "df3 = spark.createDataFrame(data, 'int')\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb5970e-a441-4d62-be6f-16e2cf64aeff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# How to replace column name\n",
    "df3 = df3.withColumnRenamed('value', 'Numbers')\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48602bc0-acb4-42a5-aa89-511718d77fdc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [],
   "source": [
    "data = [1, 23, 35, 45, 58, 69, 72, 80, 91, 3]\n",
    "df4 = spark.createDataFrame([(x,) for x in data], [\"Numbers\"])\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54882700-02da-45bf-b337-371cf5a30238",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 03"
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [(1,), (2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,)]\n",
    "df41 = spark.createDataFrame(data, [\"Id\"])\n",
    "display(df41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab56bc98-4b5a-44a3-820f-def79dea95c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5_Create a DataFrame with an Explicit Schema\n",
    "- You can define the schema explicitly using **StuctType** and **structField**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8317c4-bb45-411a-9159-566491c942ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "data = [(1, \"Mustaq\", 32, \"ADF\"),\n",
    "        (2, \"Ali\", 30, \"Databricks\"),\n",
    "        (3, \"Ahmed\", 35, \"Spark\"),\n",
    "        (4, \"Adnan\", 28, \"Python\"),\n",
    "        (5, \"Ishan\", 25, \"Java\")]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Department\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_schema = spark.createDataFrame(data, schema=schema)\n",
    "display(df_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f30472-3b12-402d-862c-967306a71ca1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [],
   "source": [
    "# Create student data with 6 rows and 6 attributes\n",
    "\n",
    "students = [['001', 'Mustaq', 23, 5.67, 67, 'Chennai'],\n",
    "            ['002', 'Ali', 25, 3.79, 34, 'Hyderabad'],\n",
    "            ['003', 'Ahmed', 27, 4.56, 17, 'Bangalore'],\n",
    "            ['004', 'Adnan', 29, 3.69, 28, 'Mumbai'],\n",
    "            ['005', 'Ishan', 23, 4.12, 54, 'Delhi'],\n",
    "            ['006', 'Atif', 25, 3.79, 25, 'Pune']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d1f4a0-476c-4708-8e8f-f5d8bf63da46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define the StructType and StructField for the below  column names\n",
    "\n",
    "schema = \"\"\"\n",
    "rollno string,\n",
    "name string,\n",
    "age int,\n",
    "height float,\n",
    "weight int,\n",
    "city string\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f802f804-0094-4da1-9cb8-c58f62103fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the DataFrame and add schema to the DataFrame\n",
    "df_schema_string = spark.createDataFrame(students,schema=schema)\n",
    "display(df_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5b6df5-602b-47df-bd78-557f3bf07870",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 03"
    }
   },
   "outputs": [],
   "source": [
    "data = [(1, 'Mustaq', [20, 30, 40]),\n",
    "        (2, 'Ali', [30, 40, 50]),\n",
    "        (3, 'Ahmed', []),\n",
    "        (4, 'Adnan', [50, 60, None])]\n",
    "         \n",
    "df_schema_def = spark.createDataFrame(data, schema = \"Id int, Name string, Marks array<int>\")\n",
    "display(df_schema_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c807308b-57af-4c25-99db-9cd360d9ea88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6_Create a DataFrame Directly from a list using row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff0f3970-f17a-41d5-9078-5d495cfb1cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [Row(Id=1, Name='Mustaq', Age=25, Department='Testing', Technology='ETL'),\n",
    "        Row(Id=2, Name='Ali', Age=23, Department='Automation Testing', Technology='Java Selenium'),\n",
    "        Row(Id=3, Name='Ahmed', Age=27, Department='Manual Testing', Technology='Python'),\n",
    "        Row(Id=4, Name='Adnan', Age=29, Department='Testing', Technology='Python'),\n",
    "        Row(Id=5, Name='Ishan', Age=23, Department='Testing', Technology='Java')]\n",
    "\n",
    "df_row = spark.createDataFrame(data)\n",
    "display(df_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f02a4cfb-7d87-41a9-8bcb-05751d0033db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 7_toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca0900d-4e0b-4408-9433-03235ccbe8e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employees = [(1, \"Mustaq\", 32000, 20, \"New York\"),\n",
    "             (2, \"Ali\", 43000, 30, \"California\"),\n",
    "             (3, \"Ahmed\", 36000, 40, \"Texas\"),\n",
    "             (4, \"Adnan\", 36000, 50, \"Florida\"),\n",
    "             (5, \"Ishan\", 36000, 60, \"New York\")]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_todf = spark.createDataFrame(employees).\\\n",
    "    toDF(\"Id\", \"Name\", \"Salary\", \"Dept Id\", \"City\")\n",
    "display(df_todf)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_How to create Pyspark Dataframe using python list",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
